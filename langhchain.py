# -*- coding: utf-8 -*-
"""Langhchain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aobrfTwII0TP0hrm7I5FMC8kCuhT3Z5n
"""

print("Hello world")

pip install langchain_groq

from langchain_groq import ChatGroq
from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.prompts import PromptTemplate
import os
os.environ["GROQ_API_KEY"] = "x"

prompt_template1 = PromptTemplate(
    input_variables=['Location'],
    template = "Suggest me some Hotel namess based on the location {location}"
)
prompt_template2 = PromptTemplate(
    input_variables=['Location'],
    template = "Suggest me recipies  based on the location {location} for the new restraunt"
)
LLM = ChatGroq(temperature=0.75, model_name = 'gemma2-9b-it')

hotelNameChain = LLMChain(llm = LLM, prompt = prompt_template1)
recipe = LLMChain(llm = LLM, prompt = prompt_template2)
chains = SimpleSequentialChain(chains=[hotelNameChain,recipe])

"""Simple Sequential chain which display one output

"""

chains.run("Indian")

""" Sequential chain which can display more than one output

"""

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, SequentialChain
from langchain_groq import ChatGroq

prompt_template1 = PromptTemplate(
    input_variables=['location'],
    template="Suggest me some hotel names based on the location {location}."
)

prompt_template2 = PromptTemplate(
    input_variables=['location'],
    template="Suggest me recipes based on the location {location} for the new restaurant."
)

LLM = ChatGroq(temperature=0.75, model_name='gemma2-9b-it')

hotelNameChain = LLMChain(llm=LLM, prompt=prompt_template1, output_key='name')
recipeChain = LLMChain(llm=LLM, prompt=prompt_template2, output_key='recipes')
chain = SequentialChain(
    chains=[hotelNameChain, recipeChain],
    input_variables=['location'],
    output_variables=['name', 'recipes'],
    verbose=True
)

result = chain({'location': 'Chinese'})
print(result)